{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T16:07:31.622069Z","iopub.execute_input":"2025-12-04T16:07:31.622232Z","iopub.status.idle":"2025-12-04T16:07:33.180189Z","shell.execute_reply.started":"2025-12-04T16:07:31.622215Z","shell.execute_reply":"2025-12-04T16:07:33.179419Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install sentence-transformers neo4j torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T16:07:33.181443Z","iopub.execute_input":"2025-12-04T16:07:33.181752Z","iopub.status.idle":"2025-12-04T16:08:52.464315Z","shell.execute_reply.started":"2025-12-04T16:07:33.181731Z","shell.execute_reply":"2025-12-04T16:08:52.463506Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting neo4j\n  Downloading neo4j-6.0.3-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading neo4j-6.0.3-py3-none-any.whl (325 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, neo4j, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed neo4j-6.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\"\"\"Generate embeddings for all entities in Neo4j and create vector index.\n\nRun this in Kaggle with GPU to speed up embedding generation.\n\nRequirements:\n- sentence-transformers\n- neo4j\n- torch (for GPU acceleration)\n\nUsage:\n    python generate_embeddings.py\n\nEnvironment variables needed:\n- NEO4J_URI\n- NEO4J_USER  \n- NEO4J_PASSWORD\n\"\"\"\nimport os\nimport torch\nfrom neo4j import GraphDatabase\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm import tqdm\nimport logging\nfrom kaggle_secrets import UserSecretsClient\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass EmbeddingGenerator:\n    \"\"\"Generate and store embeddings for Neo4j entities.\"\"\"\n    \n    def __init__(\n        self,\n        neo4j_uri: str,\n        neo4j_user: str,\n        neo4j_password: str,\n        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n        batch_size: int = 32\n    ):\n        \"\"\"Initialize generator.\n        \n        Args:\n            neo4j_uri: Neo4j connection URI\n            neo4j_user: Neo4j username\n            neo4j_password: Neo4j password\n            model_name: HuggingFace model for embeddings\n            batch_size: Batch size for embedding generation\n        \"\"\"\n        # Detect device (GPU if available)\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        logger.info(f\"Using device: {self.device}\")\n        if self.device == 'cuda':\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n            logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n            logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n        \n        # Initialize model and move to GPU (double ensure)\n        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n        self.model = SentenceTransformer(model_name, device=self.device)\n        self.model.to(self.device)  # Explicitly move model to device (belt + suspenders)\n        self.batch_size = batch_size\n        self.embedding_dim = self.model.get_sentence_embedding_dimension()\n        \n        logger.info(f\"Initialized with model: {model_name}\")\n        logger.info(f\"Embedding dimension: {self.embedding_dim}\")\n        logger.info(f\"Batch size: {batch_size}\")\n        logger.info(f\"Model device: {next(self.model.parameters()).device}\")  # Verify actual device\n    \n    def get_all_entities(self):\n        \"\"\"Fetch all entities with ALL properties from Neo4j.\"\"\"\n        query = \"\"\"\n        MATCH (n)\n        WHERE n:Country OR n:Disease OR n:Outbreak OR n:VaccinationRecord \n           OR n:Organization OR n:Vaccine OR n:PandemicEvent\n        RETURN \n            elementId(n) as id,\n            labels(n)[0] as type,\n            properties(n) as properties\n        \"\"\"\n        \n        with self.driver.session() as session:\n            result = session.run(query)\n            entities = [record.data() for record in result]\n        \n        logger.info(f\"Found {len(entities)} entities\")\n        return entities\n    \n    def create_text_representation(self, entity):\n        \"\"\"Create COMPREHENSIVE text representation for embedding.\n        \n        Includes ALL properties from the entity for maximum RAG/chatbot quality.\n        Arrays are converted to comma-separated strings.\n        \"\"\"\n        parts = []\n        entity_type = entity['type']\n        props = entity.get('properties', {})\n        \n        # Helper to format arrays\n        def format_array(arr):\n            if isinstance(arr, list):\n                return ', '.join(str(x) for x in arr if x)\n            return str(arr) if arr else ''\n        \n        # Add type\n        parts.append(f\"Entity Type: {entity_type}\")\n        \n        # ==== DISEASE - ALL PROPERTIES ====\n        if entity_type == 'Disease':\n            # Basic identifiers\n            if props.get('id'):\n                parts.append(f\"ID: {props['id']}\")\n            if props.get('name'):\n                parts.append(f\"Name: {props['name']}\")\n            if props.get('fullName'):\n                parts.append(f\"Full Name: {props['fullName']}\")\n            \n            # Medical classification codes\n            if props.get('icd10'):\n                parts.append(f\"ICD-10 Code: {props['icd10']}\")\n            if props.get('mesh'):\n                parts.append(f\"MeSH Code: {props['mesh']}\")\n            \n            # Disease category and type\n            if props.get('category'):\n                parts.append(f\"Category: {props['category']}\")\n            if props.get('pathogen'):\n                parts.append(f\"Pathogen: {props['pathogen']}\")\n            if props.get('causativeAgent'):\n                parts.append(f\"Causative Agent: {props['causativeAgent']}\")\n            if props.get('medicalSpecialty'):\n                parts.append(f\"Medical Specialty: {props['medicalSpecialty']}\")\n            \n            # Clinical information - ARRAYS\n            if props.get('symptoms'):\n                parts.append(f\"Symptoms: {format_array(props['symptoms'])}\")\n            if props.get('treatments'):\n                parts.append(f\"Treatments: {format_array(props['treatments'])}\")\n            if props.get('drugs'):\n                parts.append(f\"Drugs: {format_array(props['drugs'])}\")\n            if props.get('possibleTreatments'):\n                parts.append(f\"Possible Treatments: {format_array(props['possibleTreatments'])}\")\n            if props.get('riskFactors'):\n                parts.append(f\"Risk Factors: {format_array(props['riskFactors'])}\")\n            if props.get('transmissionMethods'):\n                parts.append(f\"Transmission Methods: {format_array(props['transmissionMethods'])}\")\n            \n            # Prevention and incubation\n            if props.get('prevention'):\n                parts.append(f\"Prevention: {props['prevention']}\")\n            if props.get('incubationPeriod'):\n                parts.append(f\"Incubation Period: {props['incubationPeriod']}\")\n            \n            # Descriptions\n            if props.get('description'):\n                parts.append(f\"Description: {props['description'][:1000]}\")\n            if props.get('wikipediaAbstract'):\n                parts.append(f\"Wikipedia Abstract: {props['wikipediaAbstract'][:1000]}\")\n            if props.get('wikipediaUrl'):\n                parts.append(f\"Wikipedia URL: {props['wikipediaUrl']}\")\n            if props.get('dbpediaUri'):\n                parts.append(f\"DBpedia URI: {props['dbpediaUri']}\")\n            if props.get('thumbnailUrl'):\n                parts.append(f\"Image: {props['thumbnailUrl']}\")\n            \n            # Status\n            if props.get('eradicated'):\n                parts.append(f\"Eradicated: {props['eradicated']}\")\n            if props.get('pandemic'):\n                parts.append(f\"Pandemic: {props['pandemic']}\")\n            if props.get('dataSource'):\n                parts.append(f\"Data Source: {props['dataSource']}\")\n                \n        # ==== COUNTRY - ALL PROPERTIES ====\n        elif entity_type == 'Country':\n            if props.get('name'):\n                parts.append(f\"Country Name: {props['name']}\")\n            if props.get('code'):\n                parts.append(f\"Country Code: {props['code']}\")\n            if props.get('iso2'):\n                parts.append(f\"ISO-2 Code: {props['iso2']}\")\n            \n            # Geographic info\n            if props.get('continent'):\n                parts.append(f\"Continent: {props['continent']}\")\n            if props.get('capital'):\n                parts.append(f\"Capital: {props['capital']}\")\n            if props.get('latitude') and props.get('longitude'):\n                parts.append(f\"Coordinates: {props['latitude']}, {props['longitude']}\")\n            if props.get('areaKm2'):\n                parts.append(f\"Area: {props['areaKm2']:,} km²\")\n            \n            # Demographics\n            if props.get('population'):\n                parts.append(f\"Population: {props['population']:,}\")\n            if props.get('officialLanguage'):\n                parts.append(f\"Official Language: {props['officialLanguage']}\")\n            \n            # Economic\n            if props.get('gdp'):\n                parts.append(f\"GDP: ${props['gdp']:,}\")\n            if props.get('lifeExpectancy'):\n                parts.append(f\"Life Expectancy: {props['lifeExpectancy']} years\")\n            \n            # External links\n            if props.get('wikipediaUrl'):\n                parts.append(f\"Wikipedia: {props['wikipediaUrl']}\")\n            if props.get('dbpediaUri'):\n                parts.append(f\"DBpedia: {props['dbpediaUri']}\")\n                \n        # ==== OUTBREAK - ALL PROPERTIES ====\n        elif entity_type == 'Outbreak':\n            if props.get('id'):\n                parts.append(f\"Outbreak ID: {props['id']}\")\n            if props.get('year'):\n                parts.append(f\"Year: {props['year']}\")\n            if props.get('date'):\n                parts.append(f\"Date: {props['date']}\")\n            \n            # Case statistics (comprehensive)\n            if props.get('cases'):\n                parts.append(f\"Cases: {int(props['cases']):,}\")\n            if props.get('deaths'):\n                parts.append(f\"Deaths: {int(props['deaths']):,}\")\n            if props.get('confirmedDeaths'):\n                parts.append(f\"Confirmed Deaths: {int(props['confirmedDeaths']):,}\")\n            if props.get('excessDeaths'):\n                parts.append(f\"Excess Deaths: {props['excessDeaths']:,}\")\n            if props.get('confidenceIntervalTop'):\n                parts.append(f\"Confidence Interval Top: {props['confidenceIntervalTop']}\")\n            if props.get('confidenceIntervalBottom'):\n                parts.append(f\"Confidence Interval Bottom: {props['confidenceIntervalBottom']}\")\n            \n            # Vaccination statistics (for VaccinationRecord outbreaks)\n            if props.get('coverage'):\n                parts.append(f\"Vaccination Coverage: {props['coverage']}%\")\n            if props.get('totalVaccinated'):\n                parts.append(f\"Total Vaccinated: {props['totalVaccinated']:,}\")\n            \n            # Links to disease/country\n            if props.get('diseaseId'):\n                parts.append(f\"Disease: {props['diseaseId']}\")\n            if props.get('diseaseName'):\n                parts.append(f\"Disease Name: {props['diseaseName']}\")\n            if props.get('countryCode'):\n                parts.append(f\"Country: {props['countryCode']}\")\n            if props.get('countryName'):\n                parts.append(f\"Country Name: {props['countryName']}\")\n                \n        # ==== ORGANIZATION - ALL PROPERTIES ====\n        elif entity_type == 'Organization':\n            if props.get('name'):\n                parts.append(f\"Organization: {props['name']}\")\n            if props.get('acronym'):\n                parts.append(f\"Acronym: {props['acronym']}\")\n            if props.get('role'):\n                parts.append(f\"Role: {props['role']}\")\n            if props.get('headquarters'):\n                parts.append(f\"Headquarters: {props['headquarters']}\")\n            if props.get('founded'):\n                parts.append(f\"Founded: {props['founded']}\")\n            if props.get('website'):\n                parts.append(f\"Website: {props['website']}\")\n                \n        # ==== VACCINE - ALL PROPERTIES ====\n        elif entity_type == 'Vaccine':\n            if props.get('name'):\n                parts.append(f\"Vaccine Name: {props['name']}\")\n            if props.get('vaccineName'):\n                parts.append(f\"Vaccine: {props['vaccineName']}\")\n            if props.get('manufacturer'):\n                parts.append(f\"Manufacturer: {props['manufacturer']}\")\n            if props.get('vaccineType'):\n                parts.append(f\"Vaccine Type: {props['vaccineType']}\")\n            if props.get('approvalDate'):\n                parts.append(f\"Approval Date: {props['approvalDate']}\")\n            if props.get('description'):\n                parts.append(f\"Description: {props['description'][:500]}\")\n                \n        # ==== VACCINATION RECORD - ALL PROPERTIES ====\n        elif entity_type == 'VaccinationRecord':\n            if props.get('id'):\n                parts.append(f\"Record ID: {props['id']}\")\n            if props.get('vaccineName'):\n                parts.append(f\"Vaccine: {props['vaccineName']}\")\n            if props.get('year'):\n                parts.append(f\"Year: {props['year']}\")\n            if props.get('coverage'):\n                parts.append(f\"Coverage: {props['coverage']}%\")\n            if props.get('totalVaccinated'):\n                parts.append(f\"Total Vaccinated: {props['totalVaccinated']:,}\")\n            if props.get('countryCode'):\n                parts.append(f\"Country: {props['countryCode']}\")\n                \n        # ==== PANDEMIC EVENT - ALL PROPERTIES ====\n        elif entity_type == 'PandemicEvent':\n            if props.get('name'):\n                parts.append(f\"Event: {props['name']}\")\n            if props.get('abstract'):\n                parts.append(f\"Description: {props['abstract'][:1000]}\")\n            if props.get('startDate'):\n                parts.append(f\"Start Date: {props['startDate']}\")\n            if props.get('deathToll'):\n                parts.append(f\"Death Toll: {props['deathToll']}\")\n            if props.get('location'):\n                parts.append(f\"Location: {props['location']}\")\n        \n        # Join all parts with separator\n        text = \" | \".join(parts) if parts else \"Unknown entity\"\n        return text\n    \n    def generate_embeddings(self, entities):\n        \"\"\"Generate embeddings for all entities using GPU if available.\"\"\"\n        logger.info(\"Generating embeddings...\")\n        logger.info(f\"Processing {len(entities)} entities in batches of {self.batch_size}\")\n        \n        # Prepare texts\n        texts = [self.create_text_representation(e) for e in entities]\n        \n        # Generate embeddings in batches with GPU acceleration\n        embeddings = self.model.encode(\n            texts,\n            batch_size=self.batch_size,\n            show_progress_bar=True,\n            convert_to_numpy=True,\n            device=self.device,  # Explicitly use GPU\n            normalize_embeddings=True  # Normalize for cosine similarity\n        )\n        \n        logger.info(f\"✓ Generated {len(embeddings)} embeddings\")\n        return embeddings\n    \n    def store_embeddings(self, entities, embeddings):\n        \"\"\"Store embeddings back to Neo4j.\n        \n        OVERWRITES existing embeddings to ensure they're up-to-date with the latest schema.\n        \"\"\"\n        logger.info(\"Storing embeddings in Neo4j (will overwrite existing)...\")\n        \n        query = \"\"\"\n        MATCH (n)\n        WHERE elementId(n) = $id\n        SET n.embedding = $embedding\n        \"\"\"\n        \n        with self.driver.session() as session:\n            for entity, embedding in tqdm(zip(entities, embeddings), total=len(entities), desc=\"Storing\"):\n                session.run(query, {\n                    \"id\": entity['id'],\n                    \"embedding\": embedding.tolist()\n                })\n        \n        logger.info(f\"✓ Stored {len(embeddings)} embeddings (overwrote any existing)\")\n    \n    def create_vector_index(self):\n        \"\"\"Create vector index for similarity search.\"\"\"\n        logger.info(\"Creating vector index...\")\n        \n        with self.driver.session() as session:\n            # Check if index exists\n            result = session.run(\"SHOW INDEXES\")\n            existing = [r['name'] for r in result]\n            \n            if 'entityEmbedding' in existing:\n                logger.info(\"Vector index 'entityEmbedding' already exists, dropping...\")\n                session.run(\"DROP INDEX entityEmbedding IF EXISTS\")\n            \n            # Create vector index for all entity types\n            query = f\"\"\"\n            CREATE VECTOR INDEX entityEmbedding IF NOT EXISTS\n            FOR (n:Country)\n            ON n.embedding\n            OPTIONS {{\n                indexConfig: {{\n                    `vector.dimensions`: {self.embedding_dim},\n                    `vector.similarity_function`: 'cosine'\n                }}\n            }}\n            \"\"\"\n            \n            try:\n                session.run(query)\n                logger.info(\"✓ Vector index 'entityEmbedding' created\")\n            except Exception as e:\n                logger.warning(f\"Note: {e}\")\n                logger.info(\"Trying alternative index creation method...\")\n                \n                # Alternative: Create for specific label\n                for label in ['Country', 'Disease', 'Outbreak', 'VaccinationRecord', \n                             'Organization', 'Vaccine', 'PandemicEvent']:\n                    try:\n                        query = f\"\"\"\n                        CREATE VECTOR INDEX entityEmbedding_{label} IF NOT EXISTS\n                        FOR (n:{label})\n                        ON n.embedding\n                        OPTIONS {{\n                            indexConfig: {{\n                                `vector.dimensions`: {self.embedding_dim},\n                                `vector.similarity_function`: 'cosine'\n                            }}\n                        }}\n                        \"\"\"\n                        session.run(query)\n                        logger.info(f\"✓ Created index for {label}\")\n                    except Exception as e2:\n                        logger.error(f\"Failed to create index for {label}: {e2}\")\n    \n    def verify_setup(self):\n        \"\"\"Verify embeddings and index are working.\"\"\"\n        logger.info(\"\\nVerifying setup...\")\n        \n        with self.driver.session() as session:\n            # Count nodes with embeddings\n            result = session.run(\"\"\"\n                MATCH (n)\n                WHERE n.embedding IS NOT NULL\n                RETURN count(n) as count\n            \"\"\")\n            count = result.single()['count']\n            logger.info(f\"✓ {count} nodes have embeddings\")\n            \n            # List indexes\n            result = session.run(\"SHOW INDEXES\")\n            indexes = [r['name'] for r in result]\n            logger.info(f\"✓ Found indexes: {', '.join(indexes)}\")\n    \n    def close(self):\n        \"\"\"Close Neo4j connection.\"\"\"\n        self.driver.close()\n    \n    def run(self):\n        \"\"\"Run the full embedding generation pipeline.\"\"\"\n        try:\n            logger.info(\"=\" * 60)\n            logger.info(\"EpiHelix - Embedding Generation\")\n            logger.info(\"=\" * 60)\n            \n            # Step 1: Fetch entities\n            entities = self.get_all_entities()\n            \n            if not entities:\n                logger.error(\"No entities found in Neo4j!\")\n                return\n            \n            # Step 2: Generate embeddings\n            embeddings = self.generate_embeddings(entities)\n            \n            # Step 3: Store embeddings\n            self.store_embeddings(entities, embeddings)\n            \n            # Step 4: Create vector index\n            self.create_vector_index()\n            \n            # Step 5: Verify\n            self.verify_setup()\n            \n            logger.info(\"\\n\" + \"=\" * 60)\n            logger.info(\"✓ Embedding generation complete!\")\n            logger.info(\"=\" * 60)\n            logger.info(\"\\nYour backend is now ready for semantic search.\")\n            \n        except Exception as e:\n            logger.error(f\"Error: {e}\", exc_info=True)\n        finally:\n            self.close()\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    # Get credentials from environment\n    user_secrets = UserSecretsClient()\n    neo4j_user = \"neo4j\"\n    neo4j_uri = user_secrets.get_secret(\"NEO4J_URI\")\n    neo4j_password = user_secrets.get_secret(\"NEO4J_PASSWORD\")\n    \n    if not neo4j_password:\n        logger.error(\"NEO4J_PASSWORD environment variable not set!\")\n        logger.info(\"\\nSet it with:\")\n        logger.info(\"  export NEO4J_PASSWORD='your-password'\")\n        return\n    \n    # Initialize and run\n    generator = EmbeddingGenerator(\n        neo4j_uri=neo4j_uri,\n        neo4j_user=neo4j_user,\n        neo4j_password=neo4j_password,\n        batch_size=256  # Larger batch size for GPU (Kaggle has 16GB GPU)\n    )\n    \n    generator.run()\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T17:49:51.397417Z","iopub.execute_input":"2025-12-04T17:49:51.397696Z","iopub.status.idle":"2025-12-04T17:57:17.930578Z","shell.execute_reply.started":"2025-12-04T17:49:51.397675Z","shell.execute_reply":"2025-12-04T17:57:17.930013Z"}},"outputs":[{"name":"stdout","text":"GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/382 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48fa5ae1ed7f4488ad105f3211feec7a"}},"metadata":{}},{"name":"stderr","text":"Storing:   2%|▏         | 2279/97681 [06:23<4:27:13,  5.95it/s]\nERROR:__main__:Error: {neo4j_code: Neo.TransientError.General.MemoryPoolOutOfMemoryError} {message: The allocation of an extra 2.0 MiB would use more than the limit 250.0 MiB. Currently using 249.1 MiB. dbms.memory.transaction.total.max threshold reached} {gql_status: 51N72} {gql_status_description: error: system configuration or operation exception - memory pool out of memory. Failed to allocate memory in a memory pool. See dbms.memory.transaction.total.max in the neo4j.conf file.}\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_48/249009054.py\", line 449, in run\n    self.store_embeddings(entities, embeddings)\n  File \"/tmp/ipykernel_48/249009054.py\", line 348, in store_embeddings\n    session.run(query, {\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/session.py\", line 320, in run\n    self._auto_result._run(\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/result.py\", line 237, in _run\n    self._attach()\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/result.py\", line 439, in _attach\n    self._connection.fetch_message()\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\", line 192, in inner\n    func(*args, **kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_bolt.py\", line 866, in fetch_message\n    res = self._process_message(tag, fields)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_bolt6.py\", line 548, in _process_message\n    response.on_failure(summary_metadata or {})\n  File \"/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\", line 262, in on_failure\n    raise self._hydrate_error(metadata)\nneo4j.exceptions.TransientError: {neo4j_code: Neo.TransientError.General.MemoryPoolOutOfMemoryError} {message: The allocation of an extra 2.0 MiB would use more than the limit 250.0 MiB. Currently using 249.1 MiB. dbms.memory.transaction.total.max threshold reached} {gql_status: 51N72} {gql_status_description: error: system configuration or operation exception - memory pool out of memory. Failed to allocate memory in a memory pool. See dbms.memory.transaction.total.max in the neo4j.conf file.}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}